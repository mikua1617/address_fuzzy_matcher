{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.function_base import average\n",
    "import textdistance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo=\"levenshtein\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suffixDict():\n",
    "    \"\"\"\n",
    "    List of common US address abbreviations to match address keywords. Key value pairs later converted into list\n",
    "    Use common abbreviations -> USPS standardized abbreviation to replace common street suffixes\n",
    "    Obtains list from https://www.usps.com/send/official-abbreviations.htm\n",
    "    \"\"\"\n",
    "    return {'trpk': 'tpke', 'forges': 'frgs', 'bypas': 'byp', 'mnr': 'mnr', 'viaduct': 'via', 'mnt': 'mt',\n",
    "            'lndng': 'lndg', 'vill': 'vlg', 'aly': 'aly', 'mill': 'ml', 'pts': 'pts', 'centers': 'ctrs', 'row': 'row', 'cnter': 'ctr',\n",
    "            'hrbor': 'hbr', 'tr': 'trl', 'lndg': 'lndg', 'passage': 'psge', 'walks': 'walk', 'frks': 'frks', 'crest': 'crst', 'meadows': 'mdws',\n",
    "            'freewy': 'fwy', 'garden': 'gdn', 'bluffs': 'blfs', 'vlg': 'vlg', 'vly': 'vly', 'fall': 'fall', 'trk': 'trak', 'squares': 'sqs',\n",
    "            'trl': 'trl', 'harbor': 'hbr', 'frry': 'fry', 'div': 'dv', 'straven': 'stra', 'cmp': 'cp', 'grdns': 'gdns', 'villg': 'vlg',\n",
    "            'meadow': 'mdw', 'trails': 'trl', 'streets': 'sts', 'prairie': 'pr', 'hts': 'hts', 'crescent': 'cres', 'pass': 'pass',\n",
    "            'ter': 'ter', 'port': 'prt', 'bluf': 'blf', 'avnue': 'ave', 'lights': 'lgts', 'rpds': 'rpds', 'harbors': 'hbrs',\n",
    "            'mews': 'mews', 'lodg': 'ldg', 'plz': 'plz', 'tracks': 'trak', 'path': 'path', 'pkway': 'pkwy', 'gln': 'gln',\n",
    "            'bot': 'btm', 'drv': 'dr', 'rdg': 'rdg', 'fwy': 'fwy', 'hbr': 'hbr', 'via': 'via', 'divide': 'dv', 'inlt': 'inlt',\n",
    "            'fords': 'frds', 'avenu': 'ave', 'vis': 'vis', 'brk': 'brk', 'rivr': 'riv', 'oval': 'oval', 'gateway': 'gtwy',\n",
    "            'stream': 'strm', 'bayoo': 'byu', 'msn': 'msn', 'knoll': 'knl', 'expressway': 'expy', 'sprng': 'spg',\n",
    "            'flat': 'flt', 'holw': 'holw', 'grden': 'gdn', 'trail': 'trl', 'jctns': 'jcts', 'rdgs': 'rdgs',\n",
    "            'tunnel': 'tunl', 'ml': 'ml', 'fls': 'fls', 'flt': 'flt', 'lks': 'lks', 'mt': 'mt', 'groves': 'grvs',\n",
    "            'vally': 'vly', 'ferry': 'fry', 'parkway': 'pkwy', 'radiel': 'radl', 'strvnue': 'stra', 'fld': 'fld',\n",
    "            'overpass': 'opas', 'plaza': 'plz', 'estate': 'est', 'mntn': 'mtn', 'lock': 'lck', 'orchrd': 'orch',\n",
    "            'strvn': 'stra', 'locks': 'lcks', 'bend': 'bnd', 'kys': 'kys', 'junctions': 'jcts', 'mountin': 'mtn',\n",
    "            'burgs': 'bgs', 'pine': 'pne', 'ldge': 'ldg', 'causway': 'cswy', 'spg': 'spg', 'beach': 'bch', 'ft': 'ft',\n",
    "            'crse': 'crse', 'motorway': 'mtwy', 'bluff': 'blf', 'court': 'ct', 'grov': 'grv', 'sprngs': 'spgs',\n",
    "            'ovl': 'oval', 'villag': 'vlg', 'vdct': 'via', 'neck': 'nck', 'orchard': 'orch', 'light': 'lgt',\n",
    "            'sq': 'sq', 'pkwy': 'pkwy', 'shore': 'shr', 'green': 'grn', 'strm': 'strm', 'islnd': 'is',\n",
    "            'turnpike': 'tpke', 'stra': 'stra', 'mission': 'msn', 'spngs': 'spgs', 'course': 'crse',\n",
    "            'trafficway': 'trfy', 'terrace': 'ter', 'hway': 'hwy', 'avenue': 'ave', 'glen': 'gln',\n",
    "            'boul': 'blvd', 'inlet': 'inlt', 'la': 'ln', 'ln': 'ln', 'frst': 'frst', 'clf': 'clf',\n",
    "            'cres': 'cres', 'brook': 'brk', 'lk': 'lk', 'byp': 'byp', 'shoar': 'shr', 'bypass': 'byp',\n",
    "            'mtin': 'mtn', 'ally': 'aly', 'forest': 'frst', 'junction': 'jct', 'views': 'vws', 'wells': 'wls', 'cen': 'ctr',\n",
    "            'exts': 'exts', 'crt': 'ct', 'corners': 'cors', 'trak': 'trak', 'frway': 'fwy', 'prarie': 'pr', 'crossing': 'xing',\n",
    "            'extn': 'ext', 'cliffs': 'clfs', 'manors': 'mnrs', 'ports': 'prts', 'gatewy': 'gtwy', 'square': 'sq', 'hls': 'hls',\n",
    "            'harb': 'hbr', 'loops': 'loop', 'mdw': 'mdw', 'smt': 'smt', 'rd': 'rd', 'hill': 'hl', 'blf': 'blf',\n",
    "            'highway': 'hwy', 'walk': 'walk', 'clfs': 'clfs', 'brooks': 'brks', 'brnch': 'br', 'aven': 'ave',\n",
    "            'shores': 'shrs', 'iss': 'iss', 'route': 'rte', 'wls': 'wls', 'place': 'pl', 'sumit': 'smt', 'pines': 'pnes',\n",
    "            'trks': 'trak', 'shoal': 'shl', 'strt': 'st', 'frwy': 'fwy', 'heights': 'hts', 'ranches': 'rnch',\n",
    "            'boulevard': 'blvd', 'extnsn': 'ext', 'mdws': 'mdws', 'hollows': 'holw', 'vsta': 'vis', 'plains': 'plns',\n",
    "            'station': 'sta', 'circl': 'cir', 'mntns': 'mtns', 'prts': 'prts', 'shls': 'shls', 'villages': 'vlgs',\n",
    "            'park': 'park', 'nck': 'nck', 'rst': 'rst', 'haven': 'hvn', 'turnpk': 'tpke', 'expy': 'expy', 'sta': 'sta',\n",
    "            'expr': 'expy', 'stn': 'sta', 'expw': 'expy', 'street': 'st', 'str': 'st', 'spurs': 'spur', 'crecent': 'cres',\n",
    "            'rad': 'radl', 'ranch': 'rnch', 'well': 'wl', 'shoals': 'shls', 'alley': 'aly', 'plza': 'plz', 'medows': 'mdws',\n",
    "            'allee': 'aly', 'knls': 'knls', 'ests': 'ests', 'st': 'st', 'anx': 'anx', 'havn': 'hvn', 'paths': 'path', 'bypa': 'byp',\n",
    "            'spgs': 'spgs', 'mills': 'mls', 'parks': 'park', 'byps': 'byp', 'flts': 'flts', 'tunnels': 'tunl', 'club': 'clb', 'sqrs': 'sqs',\n",
    "            'hllw': 'holw', 'manor': 'mnr', 'centre': 'ctr', 'track': 'trak', 'hgts': 'hts', 'rnch': 'rnch', 'crcle': 'cir', 'falls': 'fls',\n",
    "            'landing': 'lndg', 'plaines': 'plns', 'viadct': 'via', 'gdns': 'gdns', 'gtwy': 'gtwy', 'grove': 'grv', 'camp': 'cp', 'tpk': 'tpke',\n",
    "            'drive': 'dr', 'freeway': 'fwy', 'ext': 'ext', 'points': 'pts', 'exp': 'expy', 'ky': 'ky', 'courts': 'cts', 'pky': 'pkwy', 'corner': 'cor',\n",
    "            'crssing': 'xing', 'mnrs': 'mnrs', 'unions': 'uns', 'cyn': 'cyn', 'lodge': 'ldg', 'trfy': 'trfy', 'circle': 'cir', 'bridge': 'brg',\n",
    "            'dl': 'dl', 'dm': 'dm', 'express': 'expy', 'tunls': 'tunl', 'dv': 'dv', 'dr': 'dr', 'shr': 'shr', 'knolls': 'knls', 'greens': 'grns',\n",
    "            'tunel': 'tunl', 'fields': 'flds', 'common': 'cmn', 'orch': 'orch', 'crk': 'crk', 'river': 'riv', 'shl': 'shl', 'view': 'vw',\n",
    "            'crsent': 'cres', 'rnchs': 'rnch', 'crscnt': 'cres', 'arc': 'arc', 'btm': 'btm', 'blvd': 'blvd', 'ways': 'ways', 'radl': 'radl',\n",
    "            'rdge': 'rdg', 'causeway': 'cswy', 'parkwy': 'pkwy', 'juncton': 'jct', 'statn': 'sta', 'gardn': 'gdn', 'mntain': 'mtn',\n",
    "            'crssng': 'xing', 'rapid': 'rpd', 'key': 'ky', 'plns': 'plns', 'wy': 'way', 'cor': 'cor', 'ramp': 'ramp', 'throughway': 'trwy',\n",
    "            'estates': 'ests', 'ck': 'crk', 'loaf': 'lf', 'hvn': 'hvn', 'wall': 'wall', 'hollow': 'holw', 'canyon': 'cyn', 'clb': 'clb',\n",
    "            'cswy': 'cswy', 'village': 'vlg', 'cr': 'crk', 'trce': 'trce', 'cp': 'cp', 'cv': 'cv', 'ct': 'cts', 'pr': 'pr', 'frg': 'frg',\n",
    "            'jction': 'jct', 'pt': 'pt', 'mssn': 'msn', 'frk': 'frk', 'brdge': 'brg', 'cent': 'ctr', 'spur': 'spur', 'frt': 'ft', 'pk': 'park',\n",
    "            'fry': 'fry', 'pl': 'pl', 'lanes': 'ln', 'gtway': 'gtwy', 'prk': 'park', 'vws': 'vws', 'stravenue': 'stra', 'lgt': 'lgt',\n",
    "            'hiway': 'hwy', 'ctr': 'ctr', 'prt': 'prt', 'ville': 'vl', 'plain': 'pln', 'mount': 'mt', 'mls': 'mls', 'loop': 'loop',\n",
    "            'riv': 'riv', 'centr': 'ctr', 'is': 'is', 'prr': 'pr', 'vl': 'vl', 'avn': 'ave', 'vw': 'vw', 'ave': 'ave', 'spng': 'spg',\n",
    "            'hiwy': 'hwy', 'dam': 'dm', 'isle': 'isle', 'crcl': 'cir', 'sqre': 'sq', 'jct': 'jct', 'jctn': 'jct', 'mountain': 'mtn',\n",
    "            'keys': 'kys', 'parkways': 'pkwy', 'drives': 'drs', 'tunl': 'tunl', 'jcts': 'jcts', 'knl': 'knl', 'center': 'ctr',\n",
    "            'driv': 'dr', 'tpke': 'tpke', 'sumitt': 'smt', 'canyn': 'cyn', 'ldg': 'ldg', 'harbr': 'hbr', 'rest': 'rst', 'shoars': 'shrs',\n",
    "            'vist': 'vis', 'gdn': 'gdn', 'islnds': 'iss', 'hills': 'hls', 'cresent': 'cres', 'point': 'pt', 'lake': 'lk', 'vlly': 'vly',\n",
    "            'strav': 'stra', 'crossroad': 'xrd', 'bnd': 'bnd', 'strave': 'stra', 'stravn': 'stra', 'knol': 'knl', 'vlgs': 'vlgs',\n",
    "            'forge': 'frg', 'cntr': 'ctr', 'cape': 'cpe', 'height': 'hts', 'lck': 'lck', 'highwy': 'hwy', 'trnpk': 'tpke', 'rpd': 'rpd',\n",
    "            'boulv': 'blvd', 'circles': 'cirs', 'valleys': 'vlys', 'vst': 'vis', 'creek': 'crk', 'mall': 'mall', 'spring': 'spg',\n",
    "            'brg': 'brg', 'holws': 'holw', 'lf': 'lf', 'est': 'est', 'xing': 'xing', 'trace': 'trce', 'bottom': 'btm',\n",
    "            'streme': 'should_append = Falsen', 'extensions': 'exts', 'pkwys': 'pkwy', 'islands': 'iss', 'road': 'rd', 'shrs': 'shrs',\n",
    "            'roads': 'rds', 'glens': 'glns', 'springs': 'spgs', 'missn': 'msn', 'ridge': 'rdg', 'arcade': 'arc',\n",
    "            'bayou': 'byu', 'crsnt': 'cres', 'junctn': 'jct', 'way': 'way', 'valley': 'vly', 'fork': 'frk',\n",
    "            'mountains': 'mtns', 'bottm': 'btm', 'forg': 'frg', 'ht': 'hts', 'ford': 'frd', 'hl': 'hl',\n",
    "            'grdn': 'gdn', 'fort': 'ft', 'traces': 'trce', 'cnyn': 'cyn', 'cir': 'cir', 'un': 'un', 'mtn': 'mtn',\n",
    "            'flats': 'flts', 'anex': 'anx', 'gatway': 'gtwy', 'rapids': 'rpds', 'villiage': 'vlg', 'flds': 'flds',\n",
    "            'coves': 'cvs', 'rvr': 'riv', 'av': 'ave', 'pikes': 'pike', 'grv': 'grv', 'vista': 'vis', 'pnes': 'pnes',\n",
    "            'forests': 'frst', 'field': 'fld', 'branch': 'br', 'grn': 'grn', 'dale': 'dl', 'rds': 'rds', 'annex': 'anx',\n",
    "            'sqr': 'sq', 'cove': 'cv', 'squ': 'sq', 'skyway': 'skwy', 'ridges': 'rdgs', 'hwy': 'hwy', 'tunnl': 'tunl',\n",
    "            'underpass': 'upas', 'cliff': 'clf', 'lane': 'ln', 'land': 'land', 'bch': 'bch', 'dvd': 'dv', 'curve': 'curv',\n",
    "            'cpe': 'cpe', 'summit': 'smt', 'gardens': 'gdns'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function that takes user input at the beginning of the program. 1 takes a single input (a pair of addresses) from a spreadsheet\n",
    "    while 2 parses pairs of addresses from a sheet until it reaches EOF.\n",
    "    All addresses need to have exactly 6 commas that delineate the 7 parts of an address - Street line 1, Street line 2, Street line 3, City, State,\n",
    "    Country and Pincode. If one of the fields is not available for the address then any amount of whitespace or consecutive commas will work fine\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        user_input = input(\"enter 1 for matching a single pair and 2 for parsing from spreadsheet\")\n",
    "        if user_input == \"1\":\n",
    "            single_test()\n",
    "            break\n",
    "        elif user_input == \"2\":\n",
    "            multi_test()\n",
    "            break\n",
    "        else:\n",
    "            print(\"Dekh ke enter kar bro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy(row1, row2):\n",
    "    \n",
    "        \"\"\"\n",
    "        Entire logic for matching resides in this function\n",
    "        row1 and row2 are comma separated addresses sourced directly from spreadsheets. Here both addresses are fragmented according to the delimiter\n",
    "        that is specified as a comma\n",
    "        \"\"\"\n",
    "        addr1={}\n",
    "        addr2={}\n",
    "        address1 = row1\n",
    "        address2 = row2\n",
    "        \n",
    "        string1 = address1.split(\",\")\n",
    "\n",
    "        # addr1[\"street\"] = string1[0].strip()\n",
    "        # addr1[\"city\"] = string1[1].strip()\n",
    "        # addr1[\"state\"] = string1[2].strip()\n",
    "        # addr1[\"country\"] = string1[3].strip()\n",
    "        # addr1[\"pincode\"] = string1[4].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        addr1[\"street\"] = string1[0].strip()+\" \"+string1[1].strip()+\" \"+string1[2].strip()\n",
    "        addr1[\"city\"] = string1[3].strip()\n",
    "        addr1[\"state\"] = string1[4].strip()\n",
    "        addr1[\"country\"] = string1[5].strip()\n",
    "        addr1[\"pincode\"] = string1[6].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        string2 = address2.split(\",\")\n",
    "\n",
    "        # addr2[\"street\"] = string2[0].strip()\n",
    "        # addr2[\"city\"] = string2[1].strip()\n",
    "        # addr2[\"state\"] = string2[2].strip()\n",
    "        # addr2[\"country\"] = string2[3].strip()\n",
    "        # addr2[\"pincode\"] = string2[4].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        addr2[\"street\"] = string2[0].strip()+\" \"+string2[1].strip()+\" \"+string2[2].strip()\n",
    "        addr2[\"city\"] = string2[3].strip()\n",
    "        addr2[\"state\"] = string2[4].strip()\n",
    "        addr2[\"country\"] = string2[5].strip()\n",
    "        addr2[\"pincode\"] = string2[6].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        \n",
    "<br>\n",
    "        points is the weightage assigned to each component while generating the overall score. This has a 0 score for street because street<br>\n",
    "        scoring is done separately<br>\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        points = {\n",
    "            \"street\": 0,\n",
    "            \"city\": 0.3,\n",
    "            \"state\": 0.05,\n",
    "            \"country\": 0.05,\n",
    "            \"pincode\": 0.6\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        \n",
    "<br>\n",
    "        Removing all commas withing address fragments and converting all characters to lower case.<br>\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        street1 = addr1[\"street\"].lower().replace(\",\", \"\")\n",
    "        street2 = addr2[\"street\"].lower().replace(\",\", \"\")\n",
    "        \"\"\"\n",
    "        Variable declaration for a particular matching run\n",
    "        \"\"\"\n",
    "        master_keywords=[]\n",
    "        numbers1 = []\n",
    "        keywords1 = []\n",
    "        numbers2 = []\n",
    "        keywords2 = []\n",
    "        final_street_score = 0\n",
    "        score = 0\n",
    "        street_weight = 0.7\n",
    "        non_street_weight = 1-street_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        \n",
    "<br>\n",
    "        The matching process is divided into 2 parts. One for the street lines part of an address and one for the city state country and pincode.<br>\n",
    "        Each part has a final weightage in the final score which is determined by street_weight and non_street_weight respectively<br>\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if not addr1[\"pincode\"] or not addr2[\"pincode\"]:\n",
    "            \"\"\"\n",
    "            If either of the addresses does not contain a pincode, then the pincode weightage is reduced to 0.2 and the remainder is \n",
    "            equally divided over city state and country in the ratio of their existing weights.\n",
    "            i.e. 0.6 weight for pincode becomes 0.2 and 0.4 is divided among city, state and country in the ratio of 0.3:0.05:0.05. \n",
    "            This changes the ratios for city to 0.3+(0.3/(0.3+0.05+0.05))*0.4 = 0.6.\n",
    "            Similarly the weights for state and country change too to make the final weights 0.6,0.1,0.1,0.2 for city state country and pincode respectively\n",
    "            This is needed because if an address doesnt contain a pincode then the score suffers a lot despite the addresses being similar since\n",
    "            pincode has a high weightage \n",
    "            \"\"\"\n",
    "\n",
    "            # street_weight = 0.9\n",
    "            # non_street_weight = 0.1\n",
    "            sum_of_points = points['city'] + points['state']+points['country']\n",
    "            # print(\"HAHAHAHAHAHAH\")\n",
    "            revised_pincode_weight = 0.2\n",
    "            diff = points['pincode'] - revised_pincode_weight\n",
    "            \n",
    "            points[\"pincode\"] = revised_pincode_weight\n",
    "            points['city'] = points[\"city\"] + (points[\"city\"]/sum_of_points)*diff\n",
    "            points['state'] = points[\"state\"] + (points['state']/sum_of_points)*diff\n",
    "            points['country'] = points['country'] + (points['country']/sum_of_points)*diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        \n",
    "<br>\n",
    "        Converting the dictionary of key value pairs of address suffixes to a list master_keywords for easier parsing<br>\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        suffixDictitems = suffixDict()\n",
    "        for key, value in suffixDictitems.items():\n",
    "            master_keywords.append(key)\n",
    "            master_keywords.append(value)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        \n",
    "<br>\n",
    "        This fragment loops through each address and captures instances of numbers and keywords. <br>\n",
    "        <br>\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        array_string = \"\"\n",
    "        number_found=False\n",
    "        for (index,i) in enumerate(street1):\n",
    "            \"\"\"\n",
    "            Go through each character and if it is a number, then add it to the list of numbers. All consecutive occurences of a number\n",
    "            count as one number in the final list of numbers. numbers1 is the list of all numbers that occur in the address 1\n",
    "            \"\"\"\n",
    "            if i.isdigit():\n",
    "                number_found = True\n",
    "                array_string=array_string+i\n",
    "                if index == len(street1)-1:\n",
    "                    numbers1.append(array_string)\n",
    "            else:\n",
    "                if number_found:\n",
    "                    numbers1.append(array_string)\n",
    "                    array_string=\"\"\n",
    "                    number_found = False\n",
    "        \"\"\"\n",
    "        Parse through the street line (all 3) and split all parts according to a comma delimiter. Then check if a word exists in the \n",
    "        master keywords list. If it does, then add the word previous to the keyword into the keywords1 list for comparison (Riverwood drive\n",
    "        would have riverwood as the keyword for comparison)\n",
    "        \"\"\"\n",
    "        components = street1.split(\" \")\n",
    "        for count, word in enumerate(components):\n",
    "            if word in master_keywords:\n",
    "                keywords1.append(components[count-1])\n",
    "            # for keyword in master_keywords:\n",
    "            #     if textdistance.levenshtein(word, keyword) <= 1:\n",
    "            #         keywords1.append(components[count-1])\n",
    "            #         break\n",
    "        \n",
    "        print(numbers1)\n",
    "        \"\"\"\n",
    "        Same process as Address1 for Address 2\n",
    "        \"\"\"\n",
    "        array_string = \"\"\n",
    "        number_found=False\n",
    "        for (index,i) in enumerate(street2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            if i.isdigit():\n",
    "                number_found = True\n",
    "                array_string=array_string+i\n",
    "                if index == len(street2)-1:\n",
    "                    numbers2.append(array_string)\n",
    "            else:\n",
    "                if number_found:\n",
    "                    numbers2.append(array_string)\n",
    "                    array_string=\"\"\n",
    "                    number_found = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        components = street2.split(\" \")\n",
    "        for count, word in enumerate(components):\n",
    "            if word in master_keywords:\n",
    "                keywords2.append(components[count-1])\n",
    "            # for keyword in master_keywords:\n",
    "            #     if textdistance.levenshtein(word, keyword) <= 1:\n",
    "            #         keywords2.append(components[count-1])\n",
    "            #         break\n",
    "        \n",
    "        print(numbers2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        \n",
    "<br>\n",
    "        The loop below matches the list of numbers for both addresses.<br>\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        street_score_number = 0\n",
    "        similar_numbers = {}\n",
    "        l=0\n",
    "        \n",
    "        #condition for checking if any addresses dont have numbers at all\n",
    "        if not (len(numbers1) == 0 or len(numbers2) == 0):\n",
    "            \"\"\"\n",
    "            Parse through the list of numbers in address 1. For each number in address 1, parse through each number in address 2. \n",
    "            Calculate the levenshtein distance for each pair. If the distance is 0 then append the score as 1 and if distance is 1 then append 0.5 as score\n",
    "            Higher distances have no impact on final score and are considered not to be matches\n",
    "            Temp_numbers contains all the numbers and for each number in the first address, the final score is the maximum value of all the matches performed\n",
    "            with address 2 (max of temp_numbers)\n",
    "            \"\"\"\n",
    "            for i in numbers1:\n",
    "                temp_numbers = []\n",
    "                for j in numbers2:\n",
    "                    if(textdistance.levenshtein(i,j) == 0):\n",
    "                        temp_numbers.append(1)                        \n",
    "                        \n",
    "                    elif (textdistance.levenshtein(i,j) == 1):\n",
    "                        temp_numbers.append(0.5)    \n",
    "                \"\"\"\n",
    "                only create new entry for a number if it doesnt exist already and there is some score present in temp_numbers after matching for 1 \n",
    "                number in address 1.\n",
    "                similar_numbers dictionary contains all the matched numbers according to the algo above\n",
    "                \"\"\"\n",
    "                \n",
    "                \n",
    "                if not (i in similar_numbers.keys() and similar_numbers[i] == 1) and temp_numbers:\n",
    "                    l+=1\n",
    "                    similar_numbers[i] = max(temp_numbers)\n",
    "            print(similar_numbers)\n",
    "            \"\"\"\n",
    "            The score for street based on number matching is the mean of all the scores in the similar numbers dictionary\n",
    "            \"\"\"\n",
    "            print(\"street score number\", np.array(list(similar_numbers.values())).mean())\n",
    "            print(l)\n",
    "            street_score_number= 0 if math.isnan(np.array(list(similar_numbers.values())).mean()) else np.array(list(similar_numbers.values())).mean()\n",
    "            \n",
    "            \"\"\"\n",
    "            Street score based on number (street_score_number) is further modified based on the fraction of matches found compared to the numbers present\n",
    "            in the addresses. For example, if numbers1 = [\"1234\", \"999\", \"000\"], numbers2 = [\"4543\", 999\"] then matching keywords will be [\"999\": 1]\n",
    "            Scoring for this will become 1 and despite there being a lot of differences in numbers, the numbers part of the street score will be very high.\n",
    "            This is normalized by creating a multiplier for the score by dividing the number of matches (given by l) by the maximum length of the \n",
    "            numbers list for each address. In the above case, the multiplier will be 1/3 as l=1 and max length of numbers is 3. This ensures that the number\n",
    "            of matches need to include all numbers for a good match\n",
    "            \"\"\"\n",
    "            \n",
    "            street_score_number = street_score_number * (l/max(len(numbers1), len(numbers2)))\n",
    "            print(street_score_number)\n",
    "\n",
    "            # if len(similar_numbers) == min(len(numbers1), len(numbers2)):\n",
    "            #     print(\"match!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # if similar_numbers == numbers1 or similar_numbers == numbers2:\n",
    "            #     print(\"matching numbers found\", similar_numbers)\n",
    "            # else:\n",
    "            #     print(\"numbers don't match\")\n",
    "        else:\n",
    "            # levenshtein match on entire string\n",
    "            print(\"numbers don't match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        \n",
    "<br>\n",
    "        Matching for keywords<br>\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        similar_keywords = {}\n",
    "        street_score_keyword = 0\n",
    "        l=0\n",
    "        print(\"keywords 1: \", keywords1)\n",
    "        print(\"keywords 2: \", keywords2)\n",
    "        if not (len(keywords2) == 0 or len(keywords1) == 0):\n",
    "            \"\"\"\n",
    "            Matching for keywords follows a similar logic to numbers i.e. each keyword in address 1 is matched to each keyword in address 2 and the max\n",
    "            value of match is kept as the score for the word. The only difference is that here, scores are not discretized as 1 or 0.5 because keyword\n",
    "            lengths can be very high and the threshold for discrete scoring is hard to find. Instead, the score is a simple levenshtein distance normalized\n",
    "            and subtracted from 1 to get the match instead of distance out of 1\n",
    "            \"\"\"\n",
    "            for i in keywords1:\n",
    "                temp_keywords = []\n",
    "                for j in keywords2:\n",
    "                    temp_keywords.append(1-textdistance.levenshtein.normalized_distance(i,j))    \n",
    "            \n",
    "                if (i not in similar_keywords.keys()):\n",
    "                    l+=1\n",
    "                    similar_keywords[i] = max(temp_keywords)\n",
    "            \n",
    "            if similar_keywords:\n",
    "                street_score_keyword=0 if math.isnan(np.array(list(similar_keywords.values())).mean()) else np.array(list(similar_keywords.values())).mean()\n",
    "                street_score_keyword = street_score_keyword * (l/max(len(keywords1), len(keywords2)))\n",
    "            else:\n",
    "                street_score_keyword = 0\n",
    "            # print(street_score_keyword)\n",
    "\n",
    "            # if len(similar_numbers) == min(len(numbers1), len(numbers2)):\n",
    "            #     print(\"match!!\")\n",
    "        else:\n",
    "            street_score_keyword = 0\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        In addition to numbers and keyword matching, there is an additional matching score based on the jaccard index. This is a token based \n",
    "        matching algorithm that considers words as tokens and nullifies the impact of interchanged words in a string. \n",
    "        Jaccard matching is needed in the case of addresses where neither numbers or keywords are present. In such cases, number and keyword scores become\n",
    "        zero and overall match is poor despite the other parts of address being good matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        \n",
    "<br>\n",
    "                    <br>\n",
    "        street_score_token = 0<br>\n",
    "        token_weight = 0.5<br>\n",
    "        print(max(len(numbers1),len(numbers2)))<br>\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        Calculate the normalized jaccard similarity between the street lines for both addresses\n",
    "        \"\"\"\n",
    "        street_score_token = 1-textdistance.jaccard.normalized_distance(addr1['street'], addr2['street'])\n",
    "        print(\"jaccard street\",street_score_token)\n",
    "        \"\"\"\n",
    "        The jaccard score also has a variable weight system to combat cases without numbers or keywords. \n",
    "        \n",
    "        The weight for the jaccard score depends inversely on the length of the similar numbers and keywords found as a fraction of the total numbers and\n",
    "        keywords. This is needed because if the number of similar numbers is close to the number of numbers present in the addresses, then the jaccard score\n",
    "        doesn't add much value as much of the matching is already done in the number and keyword matching portion. However, if similar numbers and keywords\n",
    "        are not a significant fraction of the total numbers and keywords in the addresses, then the weight of the jaccard score increases proportionally\n",
    "        For example, if numbers1 = [\"1234\", \"999\", \"000\"], numbers2 = [\"4543\", 999\"] then matching numbers = [\"999\"]. keywords1 = [\"Raymond\", \"Whispy\"], \n",
    "        keywords2 = [\"Virginia\", \"Raymond\"] then matching keywords = [\"Raymond\"]\n",
    "        Hence the jaccard weight (token weight) = 1-0.9(1/max(3,2)+1/max(2,2))/2) = 1-0.9*(1/3+1/2)/2 = 1-0.9*0.8333/2 = 1-0.25 = 0.625\n",
    "        If the numbers2 was just [\"4543\"] then the jaccard score would increase to 1-0.9*(0+1/2)/2 = 0.775 since number matching was not conclusive as there\n",
    "        could be extra or missing numbers in one address despite being the same address\n",
    "        \"\"\"\n",
    "        \n",
    "        token_weight = 1 - 0.9 * (((len(similar_numbers)/max(len(numbers1),len(numbers2),1)) + (len(similar_keywords)/max(len(keywords1),len(keywords2),1)))/2)\n",
    "        \"\"\"\n",
    "        Number and keyword weights vary accordingly with token weight with greater weight for numbers\n",
    "        \"\"\"\n",
    "        number_weight = 0\n",
    "        keyword_weight = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        \n",
    "<br>\n",
    "        The weights assigned to numbers and keywords are variable. If numbers dont exist in either of the addresses then the weight for numbers is<br>\n",
    "        removed. Same for keywords.<br>\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if (not numbers1 and not numbers2) and (not keywords1 and not keywords2):\n",
    "            token_weight = 1\n",
    "        elif not numbers1 and not numbers2:\n",
    "            number_weight = 0\n",
    "            keyword_weight = 1-token_weight\n",
    "        elif not keywords1 and not keywords2:\n",
    "            number_weight = 1-token_weight\n",
    "            keyword_weight = 0\n",
    "        else:\n",
    "            number_weight = 0.66*(1-token_weight)\n",
    "            keyword_weight = 0.34*(1-token_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "  \n",
    "        print(street_score_keyword)\n",
    "        final_street_score = street_score_number*number_weight + street_score_keyword*keyword_weight + street_score_token*token_weight\n",
    "        print(\"final street score: \", final_street_score)\n",
    "        \n",
    "        \"\"\"\n",
    "        For the second part of the match (the non street part including city, state, country and pincode) the matching is done purely by a \n",
    "        simple levenshtein distance metric across the 2 addresses. the distance is normalized using the length of the strings and then subtracted\n",
    "        from 1 to get the match value\n",
    "        \"\"\"\n",
    "        \n",
    "        score = 0\n",
    "        \n",
    "        for key in addr1:\n",
    "            if addr1[key] == \"\" or addr2[key] == \"\":\n",
    "                continue\n",
    "            if key == \"pincode\":\n",
    "                if addr1[key] in addr2[key] or addr2[key] in addr1[key]:\n",
    "                    score = score + points[key]\n",
    "                else:\n",
    "                    score = score + (points[key]*(1-eval(\"textdistance.\"+algo).normalized_distance(addr1[key], addr2[key])))\n",
    "            else:\n",
    "                score = score + (points[key]*(1-eval(\"textdistance.\"+algo).normalized_distance(addr1[key], addr2[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        print(\"non street score: \", score)\n",
    "        total_score = (street_weight*final_street_score + non_street_weight*score)*100\n",
    "        print(\"total score: \", total_score)\n",
    "        jaccard_score = (1-textdistance.jaccard.normalized_distance(address1, address2))*100\n",
    "        print(\"jaccard score\",jaccard_score)\n",
    "        return [total_score, jaccard_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_test():\n",
    "    \"\"\"\n",
    "    this method reads Samples.ods and takes the first row from Sheet 3 and calculates the match value for one pair of addresses and prints the \n",
    "    output along with a jaccard score of the entire strings compared simultaneously\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('../singletest.csv')\n",
    "    address1 = df.Bad[0]\n",
    "    address2 = df.Original[0]\n",
    "    final_score = strategy(address1, address2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_test():\n",
    "    \"\"\"\n",
    "    This method iterates over the values from the file Samples.ods in Sheet2 and calculates the match and jaccard scores for each pair and \n",
    "    dumps the values into a file Scores.ods in Sheet1\n",
    "    \"\"\"\n",
    "    df = pd.read_excel('../Samples.ods', sheet_name=\"Sheet2\")\n",
    "    final_scores = []\n",
    "    jaccard_scores = []\n",
    "\n",
    "    # df[\"Pincode1\"] = df[\"Pincode1\"].apply(str)\n",
    "    # df[\"Pincode2\"] = df[\"Pincode2\"].apply(str)\n",
    "\n",
    "    # address_1 = df[\"Street1\"]+\",\"+df[\"City1\"]+\",\"+df[\"State1\"]+\",\"+df[\"Country1\"]+\",\"+df[\"Pincode1\"]\n",
    "    # address_2 = df[\"Street2\"]+\",\"+df[\"City2\"]+\",\"+df[\"State2\"]+\",\"+df[\"Country2\"]+\",\"+df[\"Pincode2\"]\n",
    "    \n",
    "    \n",
    "    for row1, row2 in zip(df.Bad, df.Original):\n",
    "    # for row1, row2 in zip(address_1, address_2):    \n",
    "        results = strategy(row1, row2)\n",
    "        final_scores.append(results[0])\n",
    "        jaccard_scores.append(results[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df[\"scores\"] = final_scores\n",
    "    df[\"jaccard_scores\"] = jaccard_scores\n",
    "    df.to_excel(\"../Scores.ods\", sheet_name=\"US_Scores\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
